{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser\n",
    "Parser needs 4 functions:\n",
    "- expression\n",
    "- regular expression\n",
    "- alternatives\n",
    "- list atom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![parser](img/parser.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define description and output grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grammar](img/grammar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to convert description to a grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![helper](img/desc_to_grammar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# User Instructions\n",
    "#\n",
    "# Modify the parse function so that it doesn't repeat computations.\n",
    "# You have learned about a tool in this unit that prevents \n",
    "# repetitive computations. Try using that!\n",
    "#\n",
    "# For this question, the grader will be looking for a specific \n",
    "# solution. Hint: it should only involve adding one line of code\n",
    "# (and that line should only contain 5 characters).\n",
    "\n",
    "from functools import update_wrapper\n",
    "import re\n",
    "\n",
    "\n",
    "def parse(start_symbol, text, grammar):\n",
    "    \"\"\"Example call: parse('Exp', '3*x + b', G).\n",
    "    Returns a (tree, remainder) pair. If remainder is '', it parsed the whole\n",
    "    string. Failure iff remainder is None. This is a deterministic PEG parser,\n",
    "    so rule order (left-to-right) matters. Do 'E => T op E | T', putting the\n",
    "    longest parse first; don't do 'E => T | T op E'\n",
    "    Also, no left recursion allowed: don't do 'E => E op T'\"\"\"\n",
    "\n",
    "    tokenizer = grammar[' '] + '(%s)'\n",
    "\n",
    "    def parse_sequence(sequence, text):\n",
    "        result = []\n",
    "        for atom in sequence:\n",
    "            tree, text = parse_atom(atom, text)\n",
    "            if text is None: return Fail\n",
    "            result.append(tree)\n",
    "        return result, text\n",
    "\n",
    "    @memo\n",
    "    def parse_atom(atom, text):\n",
    "        if atom in grammar:  # Non-Terminal: tuple of alternatives\n",
    "            for alternative in grammar[atom]:\n",
    "                tree, rem = parse_sequence(alternative, text)\n",
    "                if rem is not None: return [atom]+tree, rem  \n",
    "            return Fail\n",
    "        else:  # Terminal: match characters against start of text\n",
    "            m = re.match(tokenizer % atom, text)\n",
    "            return Fail if (not m) else (m.group(1), text[m.end():])\n",
    "    \n",
    "    # Body of parse:\n",
    "    return parse_atom(start_symbol, text)\n",
    "\n",
    "Fail = (None, None)\n",
    "\n",
    "# The following decorators may help you solve this question. HINT HINT!\n",
    "\n",
    "def decorator(d):\n",
    "    \"Make function d a decorator: d wraps a function fn.\"\n",
    "    def _d(fn):\n",
    "        return update_wrapper(d(fn), fn)\n",
    "    update_wrapper(_d, d)\n",
    "    return _d\n",
    "\n",
    "@decorator\n",
    "def memo(f):\n",
    "    \"\"\"Decorator that caches the return value for each call to f(args).\n",
    "    Then when called again with same args, we can just look it up.\"\"\"\n",
    "    cache = {}\n",
    "    def _f(*args):\n",
    "        try:\n",
    "            return cache[args]\n",
    "        except KeyError:\n",
    "            cache[args] = result = f(*args)\n",
    "            return result\n",
    "        except TypeError:\n",
    "            # some element of args can't be a dict key\n",
    "            return f(args)\n",
    "    return _f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.crockford.com/mckeeman.html\n",
    "\n",
    "https://www.json.org/json-en.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq result ['[]'] \n",
      "debug: array ['[]'] reminder \n",
      "seq result [['array', '[]']] \n",
      "debug: value [['array', '[]']] reminder \n",
      "(['value', ['array', '[]']], '')\n",
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# User Instructions\n",
    "#\n",
    "# In this problem, you will be using many of the tools and techniques\n",
    "# that you developed in unit 3 to write a grammar that will allow\n",
    "# us to write a parser for the JSON language.\n",
    "#\n",
    "# You will have to visit json.org to see the JSON grammar. It is not\n",
    "# presented in the correct format for our grammar function, so you\n",
    "# will need to translate it.\n",
    "\n",
    "# ---------------\n",
    "# Provided functions\n",
    "#\n",
    "# These are all functions that were built in unit 3. They will help\n",
    "# you as you write the grammar.  Add your code at line 102.\n",
    "\n",
    "from functools import update_wrapper\n",
    "from string import split\n",
    "import re\n",
    "\n",
    "def grammar(description, whitespace=r'\\s*'):\n",
    "    \"\"\"Convert a description to a grammar.  Each line is a rule for a\n",
    "    non-terminal symbol; it looks like this:\n",
    "        Symbol =>  A1 A2 ... | B1 B2 ... | C1 C2 ...\n",
    "    where the right-hand side is one or more alternatives, separated by\n",
    "    the '|' sign.  Each alternative is a sequence of atoms, separated by\n",
    "    spaces.  An atom is either a symbol on some left-hand side, or it is\n",
    "    a regular expression that will be passed to re.match to match a token.\n",
    "    Notation for *, +, or ? not allowed in a rule alternative (but ok\n",
    "    within a token). Use '\\' to continue long lines.  You must include spaces\n",
    "    or tabs around '=>' and '|'. That's within the grammar description itself.\n",
    "    The grammar that gets defined allows whitespace between tokens by default;\n",
    "    specify '' as the second argument to grammar() to disallow this (or supply\n",
    "    any regular expression to describe allowable whitespace between tokens).\"\"\"\n",
    "    G = {' ': whitespace}\n",
    "    description = description.replace('\\t', ' ') # no tabs!\n",
    "    for line in split(description, '\\n'):\n",
    "        if not line: continue\n",
    "        lhs, rhs = split(line, ' => ', 1)\n",
    "        alternatives = split(rhs, ' | ')\n",
    "        G[lhs] = tuple(map(split, alternatives))\n",
    "    #print G\n",
    "    return G\n",
    "\n",
    "\n",
    "def decorator(d):\n",
    "    \"Make function d a decorator: d wraps a function fn.\"\n",
    "    def _d(fn):\n",
    "        return update_wrapper(d(fn), fn)\n",
    "    update_wrapper(_d, d)\n",
    "    return _d\n",
    "\n",
    "@decorator\n",
    "def memo(f):\n",
    "    \"\"\"Decorator that caches the return value for each call to f(args).\n",
    "    Then when called again with same args, we can just look it up.\"\"\"\n",
    "    cache = {}\n",
    "    def _f(*args):\n",
    "        try:\n",
    "            return cache[args]\n",
    "        except KeyError:\n",
    "            cache[args] = result = f(*args)\n",
    "            return result\n",
    "        except TypeError:\n",
    "            # some element of args can't be a dict key\n",
    "            return f(args)\n",
    "    return _f\n",
    "\n",
    "def parse(start_symbol, text, grammar):\n",
    "    \"\"\"Example call: parse('Exp', '3*x + b', G).\n",
    "    Returns a (tree, remainder) pair. If remainder is '', it parsed the whole\n",
    "    string. Failure iff remainder is None. This is a deterministic PEG parser,\n",
    "    so rule order (left-to-right) matters. Do 'E => T op E | T', putting the\n",
    "    longest parse first; don't do 'E => T | T op E'\n",
    "    Also, no left recursion allowed: don't do 'E => E op T'\"\"\"\n",
    "\n",
    "    tokenizer = grammar[' '] + '(%s)'\n",
    "\n",
    "    def parse_sequence(sequence, text):\n",
    "        result = []\n",
    "        for atom in sequence:\n",
    "            tree, text = parse_atom(atom, text)\n",
    "            if text is None: return Fail\n",
    "            result.append(tree)\n",
    "        print 'seq result', result, text\n",
    "        return result, text\n",
    "\n",
    "    @memo\n",
    "    def parse_atom(atom, text):\n",
    "        if atom in grammar:  # Non-Terminal: tuple of alternatives\n",
    "            for alternative in grammar[atom]:\n",
    "                tree, rem = parse_sequence(alternative, text)\n",
    "                if rem is not None: \n",
    "                    print 'debug:', atom, tree, 'reminder', rem\n",
    "                    return [atom]+tree, rem\n",
    "            return Fail\n",
    "        else:  # Terminal: match characters against start of text\n",
    "            m = re.match(tokenizer % atom, text)\n",
    "            return Fail if (not m) else (m.group(1), text[m.end():])\n",
    "\n",
    "    # Body of parse:\n",
    "    return parse_atom(start_symbol, text)\n",
    "\n",
    "Fail = (None, None)\n",
    "\n",
    "JSON = grammar(\"\"\"\n",
    "object => { } | { members }\n",
    "members => pair , members | pair\n",
    "pair => string : value\n",
    "array => [[] elements []] | [[]]\n",
    "elements => value , elements | value\n",
    "value => string | number | object | array | true | false | null\n",
    "string => \"[^\"]*\"\n",
    "number => int frac exp | int frac | int exp | int\n",
    "int => -?[1-9][0-9]*\n",
    "frac => [.][0-9]*\n",
    "exp => [eE][-+]?[0-9]*\n",
    "\"\"\", whitespace='\\s*')\n",
    "\n",
    "def json_parse(text):\n",
    "    r = parse('value', text, JSON)\n",
    "    print r\n",
    "    return r\n",
    "\n",
    "def test():\n",
    "    #json_parse('[3]')\n",
    "    json_parse('[]')\n",
    "\n",
    "#     assert json_parse('[\"testing\", \"baba\"]') == (\n",
    "#         ['value', ['array', '[', ['elements', ['value', ['string', '\"testing\"']], ',', \n",
    "#                                   ['elements', ['value', ['string', '\"baba\"']]]], ']']], '')\n",
    "    \n",
    "#     assert json_parse('[\"testing\", 1, 2, 3]') == (\n",
    "#                        ['value', ['array', '[', ['elements', ['value',\n",
    "#                        ['string', '\"testing\"']], ',', ['elements', ['value', ['number',\n",
    "#                        ['int', '1']]], ',', ['elements', ['value', ['number',\n",
    "#                        ['int', '2']]], ',', ['elements', ['value', ['number',\n",
    "#                        ['int', '3']]]]]]], ']']], '')\n",
    "\n",
    "#     assert json_parse('-123.456e+789') == (\n",
    "#                        ['value', ['number', ['int', '-123'], ['frac', '.456'], ['exp', 'e+789']]], '')\n",
    "\n",
    "#     assert json_parse('{\"age\": 21, \"state\":\"CO\",\"occupation\":\"rides the rodeo\"}') == (\n",
    "#                       ['value', ['object', '{', ['members', ['pair', ['string', '\"age\"'],\n",
    "#                        ':', ['value', ['number', ['int', '21']]]], ',', ['members',\n",
    "#                       ['pair', ['string', '\"state\"'], ':', ['value', ['string', '\"CO\"']]],\n",
    "#                       ',', ['members', ['pair', ['string', '\"occupation\"'], ':',\n",
    "#                       ['value', ['string', '\"rides the rodeo\"']]]]]], '}']], '')\n",
    "    return 'tests pass'\n",
    "\n",
    "print test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "json_parse('[]')\n",
    "\n",
    "seq result ['[]'] \n",
    "debug: ['[[]]'] array ['[]'] reminder \n",
    "seq result [['array', '[]']] \n",
    "debug: ['array'] value [['array', '[]']] reminder \n",
    "(['value', ['array', '[]']], '')\n",
    "tests pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3], 4]\n"
     ]
    }
   ],
   "source": [
    "# concatenate list to list\n",
    "a = [[3]]\n",
    "b = [4]\n",
    "print a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ ] is special char, it means a char set, so it search \"[\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "('[',)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = '[]'\n",
    "m = re.match('([[])', text)\n",
    "print m.group(1)\n",
    "print m.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
